# MEDICAL-TEXT-DATA-CLASSIFICATION

## Overview

This project involves text classification using machine learning techniques on medical research papers. The pipeline includes text extraction, preprocessing, feature engineering, model training, evaluation, and visualization.

## Prerequisites

Ensure that your environment meets the following requirements:

- Python 3.8 or later
- Required libraries (install using `requirements.txt`)
- Access to the dataset (PDF files)

## Installation

1. Clone this repository:
   ```sh
   git clone <repository-url>
   cd <repository-folder>
   ```
2. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```

## Running the Program

Follow these steps to execute the pipeline:

1. **Extract Text from PDFs:**

   - The script loads and extracts text from the research papers PDF

2. **Text Preprocessing:**

   - Cleans text by removing headers, footers, numbers, punctuation, and stopwords.
   - Performs tokenization, stemming, and lemmatization.

3. **Feature Engineering:**

   - Uses Bag-of-Words (BoW) and TF-IDF vectorization.
   - Encodes labels for classification.

4. **Model Training and Evaluation:**

   - Implements classifiers: SVM, Random Forest, Na√Øve Bayes, k-NN, and XGBoost.
   - Performs 10-fold cross-validation.
   - Trains the best-performing model on the dataset.

5. **Error Analysis and Visualization:**

   - Displays classification reports and confusion matrices.
   - Identifies and visualizes misclassified samples.

## Execution Order

Run the following code cells in order:

1. `importing libraries`: Download required libraries
2. `PDF extraction and preprocessing`: Extracts, cleans, and partitions text.
3. `Feature Engineering: Label Encoding & Text Vectorization`: Transforms text into numerical features.
4. `Model Training & Evaluation with Cross-Validation`: Trains and evaluates models.
5. `error_analysis`: Analyzes performance of the model.
6. `Misclassified samples identification`: Analyzes misclassified samples.
7. `visualization.py`: Generates plots and insights.

## Environment Variables

- Adjust file paths inside `file_paths` dictionary before execution.
- Set dataset location according to your environment.

## Output

- Cleaned dataset saved as `cleaned_data.csv`.
- Model performance metrics displayed in the console.
- Visualizations saved as images.
